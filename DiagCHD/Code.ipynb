{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3eb9e5-5913-4660-b3ac-502101210a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import CategoricalCrossentropy\n",
    "import os\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.applications.xception import Xception\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def dice_coeff(x, target, ignore_index = -100, epsilon=1e-6):\n",
    "    # Average of Dice coefficient for all batches, or for a single mask\n",
    "    # 计算一个batch中所有图片某个类别的dice_coefficient\n",
    "    d = 0.\n",
    "    batch_size = tf.shape(x)[0]\n",
    "    for i in range(batch_size):\n",
    "        x_i = tf.reshape(x[i], [-1])\n",
    "        t_i = tf.reshape(target[i], [-1])\n",
    "        if ignore_index >= 0:\n",
    "            # 找出mask中不为ignore_index的区域\n",
    "            roi_mask = tf.not_equal(t_i, ignore_index)\n",
    "            x_i = tf.boolean_mask(x_i, roi_mask)\n",
    "            t_i = tf.boolean_mask(t_i, roi_mask)\n",
    "        inter = tf.reduce_sum(tf.multiply(x_i, t_i))\n",
    "        sets_sum = tf.reduce_sum(x_i) + tf.reduce_sum(t_i)\n",
    "        if sets_sum == 0:\n",
    "            sets_sum = 2 * inter\n",
    "\n",
    "        d += (2 * inter + epsilon) / (sets_sum + epsilon)\n",
    "\n",
    "    return d / tf.cast(batch_size, dtype=tf.float32)\n",
    "\n",
    "\n",
    "def multiclass_dice_coeff(x, target, ignore_index = -100, epsilon=1e-6):\n",
    "    \"\"\"Average of Dice coefficient for all classes\"\"\"\n",
    "    dice = 0.\n",
    "    for channel in range(tf.shape(x)[3]):\n",
    "        dice += dice_coeff(x[:,:,:,channel], target[:,:,:,channel], ignore_index, epsilon)\n",
    "\n",
    "    return dice / tf.cast(tf.shape(x)[3], dtype=tf.float32)\n",
    "\n",
    "def dice_loss(x, target, multiclass = False, ignore_index = -100):\n",
    "    # Dice loss (objective to minimize) between 0 and 1\n",
    "    fn = multiclass_dice_coeff if multiclass else dice_coeff\n",
    "    return 1 - fn(x, target, ignore_index=ignore_index)\n",
    "\n",
    "def ce_dice_loss(y_true, y_pred):\n",
    "    ce_loss = CategoricalCrossentropy()(y_true, y_pred)  # 多类别交叉熵损失\n",
    "    dice_coef = dice_loss(y_pred,y_true,multiclass=True)  # Dice损失\n",
    "\n",
    "    return ce_loss + dice_coef\n",
    "\n",
    "def dice_coef(x, target, multiclass = True, ignore_index = -100):\n",
    "    # Dice loss (objective to minimize) between 0 and 1\n",
    "    fn = multiclass_dice_coeff if multiclass else dice_coeff\n",
    "    return fn(x, target, ignore_index=ignore_index)\n",
    "\n",
    "model = load_model('/HOME/scw7212/run/AZ/Code/congenital_heart_disease/Code/1_Xception图像分割/CBAM注意力机制/new/callbacks_EarlyStopping_a5/callbacks_EarlyStopping.h5',\n",
    "                   custom_objects={'ce_dice_loss':ce_dice_loss,'dice_coef':dice_coef})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e589b8a-3792-4e29-95ea-88752c7d3d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('自定义分割模型权重.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b8e409-fe54-4864-ac1c-bad1a0de180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.applications.xception import Xception\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adagrad, Adam\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd076f74-16cc-4d4f-862a-fd8a15802be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集的加载\n",
    "height = 576  #图片的高度\n",
    "width = 768  #图片的长度\n",
    "channels = 3  #彩色图片\n",
    "batch_size = 4*3  #每一次49个图片\n",
    "num_classes = 3  #最后是7分类\n",
    "SEED = 666  # 用于限制多个输入图片的label保持一致，训练集有一个随机扰乱的\n",
    "epochs = 300\n",
    "img_size_input_1 = (height, width)  # 第一个输入图片的维度大小\n",
    "img_size_input_2 = (height, width)  # 第二个输入图片的维度大小\n",
    "# 数据集加载\n",
    "train_dir_input_1 = r\"/HOME/scw7212/run/AZ/Code/congenital_heart_disease/Code/Dataset/Train/IMAGE\"\n",
    "valid_dir_input_1 = r\"/HOME/scw7212/run/AZ/Code/congenital_heart_disease/Code/Dataset/Test/IMAGE\"\n",
    "train_dir_input_2 = r\"/HOME/scw7212/run/AZ/Code/congenital_heart_disease/Code/Dataset/Train/MASK\"\n",
    "valid_dir_input_2 = r\"/HOME/scw7212/run/AZ/Code/congenital_heart_disease/Code/Dataset/Test/MASK\"\n",
    "\n",
    "train_datagen_input_1 = keras.preprocessing.image.ImageDataGenerator(  #这个是专门进行图片进行强化操作处理的,传入一个目录就可以将图片转化成你需要的，且进行数据增强，样本会进行叠加的\n",
    "    rescale=1. / 255, )  #这样就可以新创建出图片了\n",
    "train_generator_input_1 = train_datagen_input_1.flow_from_directory(\n",
    "    train_dir_input_1,  #上面的ImageDataGenerator只是一个迭代器，将图片转化成像素值，这个方法flow_from_directory就可以批量取数据\n",
    "    target_size=img_size_input_1,  #图片大小规定到这个高宽\n",
    "    batch_size=batch_size,  #每一个批次batch_size个图片进行上面的操作\n",
    "    seed=SEED,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\")  #这个指定二进制标签，我们用了binary_crossentropy损失函数\n",
    "valid_datagen_input_1 = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1. / 255)  #验证集不用添加图片，只需要将图片像素值进行规定\n",
    "valid_generator_input_1 = valid_datagen_input_1.flow_from_directory(\n",
    "    valid_dir_input_1,\n",
    "    target_size=img_size_input_1,\n",
    "    batch_size=batch_size,\n",
    "    seed=SEED,\n",
    "    shuffle=False,\n",
    "    class_mode=\"categorical\")\n",
    "\n",
    "# mask创建\n",
    "train_datagen_input_2 = keras.preprocessing.image.ImageDataGenerator()  #这样就可以新创建出图片了\n",
    "train_generator_input_2 = train_datagen_input_2.flow_from_directory(\n",
    "    train_dir_input_2,  #上面的ImageDataGenerator只是一个迭代器，将图片转化成像素值，这个方法flow_from_directory就可以批量取数据\n",
    "    target_size=img_size_input_2,  #图片大小规定到这个高宽\n",
    "    batch_size=batch_size,  #每一个批次batch_size个图片进行上面的操作\n",
    "    seed=SEED,\n",
    "    shuffle=True,\n",
    "    color_mode='grayscale',\n",
    "    class_mode=\"categorical\")  #这个指定二进制标签，我们用了binary_crossentropy损失函数\n",
    "valid_datagen_input_2 = keras.preprocessing.image.ImageDataGenerator()  #验证集不用添加图片，只需要将图片像素值进行规定\n",
    "valid_generator_input_2 = valid_datagen_input_2.flow_from_directory(\n",
    "    valid_dir_input_2,\n",
    "    target_size=img_size_input_2,\n",
    "    batch_size=batch_size,\n",
    "    seed=SEED,\n",
    "    shuffle=False,\n",
    "    color_mode='grayscale',\n",
    "    class_mode=\"categorical\")\n",
    "train_num_input_1 = train_generator_input_1.samples  #获取训练样本总数\n",
    "train_num_input_2 = train_generator_input_2.samples\n",
    "valid_num_input_1 = valid_generator_input_1.samples  #获取训练样本总数\n",
    "valid_num_input_2 = valid_generator_input_2.samples\n",
    "print(\"样本总数为：\")\n",
    "print(train_num_input_1, train_num_input_2, valid_num_input_1,\n",
    "    valid_num_input_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdbfe72-e50f-4920-bb67-7073620be39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集的加载\n",
    "height = 576  #图片的高度\n",
    "width = 768  #图片的长度\n",
    "channels = 3  #彩色图片\n",
    "batch_size = 6  #每一次49个图片\n",
    "test_size=1\n",
    "num_classes = 3  #最后是7分类\n",
    "SEED = 666  # 用于限制多个输入图片的label保持一致，训练集有一个随机扰乱的\n",
    "epochs = 300\n",
    "img_size_input_1 = (height, width)  # 第一个输入图片的维度大小\n",
    "img_size_input_2 = (height, width)  # 第二个输入图片的维度大小\n",
    "# 数据集加载\n",
    "train_dir_input_1 = r\"/HOME/scw7212/run/AZ/Code/congenital_heart_disease/Code/Dataset/Train/IMAGE\"\n",
    "valid_dir_input_1 = r\"/HOME/scw7212/run/AZ/Code/congenital_heart_disease/Code/Dataset/Test/IMAGE\"\n",
    "train_dir_input_2 = r\"/HOME/scw7212/run/AZ/Code/congenital_heart_disease/Code/Dataset/Train/MASK\"\n",
    "valid_dir_input_2 = r\"/HOME/scw7212/run/AZ/Code/congenital_heart_disease/Code/Dataset/Test/MASK\"\n",
    "\n",
    "train_datagen_input_1 = keras.preprocessing.image.ImageDataGenerator(  #这个是专门进行图片进行强化操作处理的,传入一个目录就可以将图片转化成你需要的，且进行数据增强，样本会进行叠加的\n",
    "    rescale=1. / 255, )  #这样就可以新创建出图片了\n",
    "train_generator_input_1 = train_datagen_input_1.flow_from_directory(\n",
    "    train_dir_input_1,  #上面的ImageDataGenerator只是一个迭代器，将图片转化成像素值，这个方法flow_from_directory就可以批量取数据\n",
    "    target_size=img_size_input_1,  #图片大小规定到这个高宽\n",
    "    batch_size=batch_size,  #每一个批次batch_size个图片进行上面的操作\n",
    "    seed=SEED,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\")  #这个指定二进制标签，我们用了binary_crossentropy损失函数\n",
    "valid_datagen_input_1 = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1. / 255)  #验证集不用添加图片，只需要将图片像素值进行规定\n",
    "valid_generator_input_1 = valid_datagen_input_1.flow_from_directory(\n",
    "    valid_dir_input_1,\n",
    "    target_size=img_size_input_1,\n",
    "    batch_size=test_size,\n",
    "    seed=SEED,\n",
    "    shuffle=False,\n",
    "    class_mode=\"categorical\")\n",
    "\n",
    "# mask创建\n",
    "train_datagen_input_2 = keras.preprocessing.image.ImageDataGenerator()  #这样就可以新创建出图片了\n",
    "train_generator_input_2 = train_datagen_input_2.flow_from_directory(\n",
    "    train_dir_input_2,  #上面的ImageDataGenerator只是一个迭代器，将图片转化成像素值，这个方法flow_from_directory就可以批量取数据\n",
    "    target_size=img_size_input_2,  #图片大小规定到这个高宽\n",
    "    batch_size=batch_size,  #每一个批次batch_size个图片进行上面的操作\n",
    "    seed=SEED,\n",
    "    shuffle=True,\n",
    "    color_mode='grayscale',\n",
    "    class_mode=\"categorical\")  #这个指定二进制标签，我们用了binary_crossentropy损失函数\n",
    "valid_datagen_input_2 = keras.preprocessing.image.ImageDataGenerator()  #验证集不用添加图片，只需要将图片像素值进行规定\n",
    "valid_generator_input_2 = valid_datagen_input_2.flow_from_directory(\n",
    "    valid_dir_input_2,\n",
    "    target_size=img_size_input_2,\n",
    "    batch_size=test_size,\n",
    "    seed=SEED,\n",
    "    shuffle=False,\n",
    "    color_mode='grayscale',\n",
    "    class_mode=\"categorical\")\n",
    "train_num_input_1 = train_generator_input_1.samples  #获取训练样本总数\n",
    "train_num_input_2 = train_generator_input_2.samples\n",
    "valid_num_input_1 = valid_generator_input_1.samples  #获取训练样本总数\n",
    "valid_num_input_2 = valid_generator_input_2.samples\n",
    "print(\"样本总数为：\")\n",
    "print(train_num_input_1, train_num_input_2, valid_num_input_1,\n",
    "    valid_num_input_2)\n",
    "\n",
    "def cbam_block(cbam_feature, LayerName='', ratio=8):\n",
    "    \"\"\"Contains the implementation of Convolutional Block Attention Module(CBAM) block.\n",
    "    As described in https://arxiv.org/abs/1807.06521.\n",
    "    \"\"\"\n",
    "\n",
    "    cbam_feature = channel_attention(cbam_feature, ratio, LayerName)\n",
    "    cbam_feature = spatial_attention(cbam_feature, LayerName)\n",
    "    return cbam_feature\n",
    "\n",
    "def channel_attention(input_feature, ratio=8, LayerName=\"\"):\n",
    "\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "    channel = input_feature.shape[channel_axis]\n",
    "\n",
    "    shared_layer_one = Dense(channel // ratio,\n",
    "                             activation='relu',\n",
    "                             kernel_initializer='he_normal',\n",
    "                             use_bias=True,\n",
    "                             bias_initializer='zeros',\n",
    "                             name=LayerName + 'Dense_1')\n",
    "    shared_layer_two = Dense(channel,\n",
    "                             kernel_initializer='he_normal',\n",
    "                             use_bias=True,\n",
    "                             bias_initializer='zeros',\n",
    "                             name=LayerName + 'Dense_2')\n",
    "\n",
    "    avg_pool = GlobalAveragePooling2D(\n",
    "        name=LayerName + 'GlobalAveragePooling2D_1')(input_feature)\n",
    "    avg_pool = Reshape((1, 1, channel),\n",
    "                       name=LayerName + 'Reshape_1')(avg_pool)\n",
    "    assert avg_pool.shape[1:] == (1, 1, channel)\n",
    "    avg_pool = shared_layer_one(avg_pool)\n",
    "    assert avg_pool.shape[1:] == (1, 1, channel // ratio)\n",
    "    avg_pool = shared_layer_two(avg_pool)\n",
    "    assert avg_pool.shape[1:] == (1, 1, channel)\n",
    "\n",
    "    max_pool = GlobalMaxPooling2D(\n",
    "        name=LayerName + 'GlobalAveragePooling2D_2')(input_feature)\n",
    "    max_pool = Reshape((1, 1, channel),\n",
    "                       name=LayerName + 'Reshape_2')(max_pool)\n",
    "    assert max_pool.shape[1:] == (1, 1, channel)\n",
    "    max_pool = shared_layer_one(max_pool)\n",
    "    assert max_pool.shape[1:] == (1, 1, channel // ratio)\n",
    "    max_pool = shared_layer_two(max_pool)\n",
    "    assert max_pool.shape[1:] == (1, 1, channel)\n",
    "\n",
    "    cbam_feature = Add(name=LayerName + 'Add')([avg_pool, max_pool])\n",
    "    cbam_feature = Activation('sigmoid',\n",
    "                              name=LayerName + 'Activation')(cbam_feature)\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "    print(input_feature.shape, cbam_feature.shape,\n",
    "          multiply([input_feature, cbam_feature]).shape)\n",
    "    return multiply([input_feature, cbam_feature])\n",
    "\n",
    "def spatial_attention(input_feature, LayerName):\n",
    "    kernel_size = 7\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        channel = input_feature.shape[1]\n",
    "        cbam_feature = Permute((2, 3, 1))(input_feature)\n",
    "    else:\n",
    "        channel = input_feature.shape[-1]\n",
    "        cbam_feature = input_feature\n",
    "\n",
    "    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True),\n",
    "                      name=LayerName + 'Lambda_1')(cbam_feature)\n",
    "    assert avg_pool.shape[-1] == 1\n",
    "    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True),\n",
    "                      name=LayerName + 'Lambda_2')(cbam_feature)\n",
    "    assert max_pool.shape[-1] == 1\n",
    "    concat = Concatenate(axis=3, name=LayerName +\n",
    "                         'Concatenate')([avg_pool, max_pool])\n",
    "    assert concat.shape[-1] == 2\n",
    "    cbam_feature = Conv2D(filters=1,\n",
    "                          kernel_size=kernel_size,\n",
    "                          strides=1,\n",
    "                          padding='same',\n",
    "                          activation='sigmoid',\n",
    "                          kernel_initializer='he_normal',\n",
    "                          use_bias=False,\n",
    "                          name=LayerName + 'Conv2D_1')(concat)\n",
    "    assert cbam_feature.shape[-1] == 1\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "    print(input_feature.shape, cbam_feature.shape,\n",
    "          multiply([input_feature, cbam_feature]).shape)\n",
    "    return multiply([input_feature, cbam_feature])\n",
    "\n",
    "def generate_data_generator(generator_input_1, generator_input_2):\n",
    "    while True:\n",
    "        x_data, label_x = generator_input_1.next()\n",
    "        mask_data, label_mask = generator_input_2.next()\n",
    "        # 这一句代码代表输入的多个类型的图片label是一致的\n",
    "        assert np.array(label_x).all() == np.array(label_mask).all(), '数据集产出失败'\n",
    "        # 代表输入的图片与输出的label的维度指定\n",
    "        yield np.array(x_data),{\"Seg\":tf.one_hot(np.array(tf.squeeze(mask_data,axis=-1)),depth=3),\n",
    "                                \"SegModel_Xception\":label_x}\n",
    "\n",
    "def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n",
    "    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    if activation == True:\n",
    "        x = LeakyReLU(alpha=0.1)(x)\n",
    "    return x\n",
    "\n",
    "def residual_block(blockInput, num_filters=16):\n",
    "    x = LeakyReLU(alpha=0.1)(blockInput)\n",
    "    x = BatchNormalization()(x)\n",
    "    blockInput = BatchNormalization()(blockInput)\n",
    "    x = convolution_block(x, num_filters, (3,3))\n",
    "    x = convolution_block(x, num_filters, (3,3), activation=False)\n",
    "    x = Add()([x, blockInput])\n",
    "    return x\n",
    "\n",
    "\n",
    "def Unet_Xception_ResNetBlock(nClasses, input_height=224, input_width=224):\n",
    "\n",
    "    backbone = Xception(input_shape=(input_height, input_width, 3), weights='imagenet', include_top=False)\n",
    "\n",
    "    inputs = backbone.input\n",
    "\n",
    "    conv4 = backbone.layers[121].output#下采样4倍\n",
    "    conv4 = LeakyReLU(alpha=0.1)(conv4)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "\n",
    "\n",
    "    # Middle\n",
    "    convm = Conv2D(16*32, (3, 3), activation=None, padding=\"same\")(pool4)\n",
    "    convm = residual_block(convm, 16*32)\n",
    "    convm = residual_block(convm, 16*32)\n",
    "    convm = LeakyReLU(alpha=0.1,name='ClsLeakyReLU')(convm)\n",
    "\n",
    "    # 8 -> 16\n",
    "    deconv4 = Conv2DTranspose(16*16, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    # 针对主干网络输出的内容进行预测\n",
    "    print(deconv4.shape, conv4.shape)\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    uconv4 = cbam_block(uconv4,'conv4')\n",
    "\n",
    "    uconv4 = Conv2D(16*16, (3, 3), activation=None, padding=\"same\")(uconv4)\n",
    "    uconv4 = residual_block(uconv4, 16 * 16)\n",
    "    uconv4 = residual_block(uconv4, 16*16)\n",
    "    uconv4 = LeakyReLU(alpha=0.1)(uconv4)\n",
    "\n",
    "    # 16 -> 32\n",
    "    deconv3 = Conv2DTranspose(16*8, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "    conv3 = backbone.layers[31].output\n",
    "    print(deconv3.shape, conv3.shape)\n",
    "    uconv3 = concatenate([deconv3, conv3])    \n",
    "    uconv3 = cbam_block(uconv3,'conv3')\n",
    "\n",
    "    uconv3 = Conv2D(16*8, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
    "    uconv3 = residual_block(uconv3, 16*8)\n",
    "    uconv3 = residual_block(uconv3, 16*8)\n",
    "    uconv3 = LeakyReLU(alpha=0.1)(uconv3)\n",
    "\n",
    "    # 32 -> 64\n",
    "    deconv2 = Conv2DTranspose(16*4, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
    "    conv2 = backbone.layers[21].output\n",
    "    conv2 = ZeroPadding2D(((1,0),(1,0)))(conv2)\n",
    "    print(deconv2.shape, conv2.shape)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "    uconv2 = cbam_block(uconv2,'conv2')\n",
    "\n",
    "    uconv2 = Conv2D(16*4, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
    "    uconv2 = residual_block(uconv2, 16*4)\n",
    "    uconv2 = residual_block(uconv2, 16*4)\n",
    "    uconv2 = LeakyReLU(alpha=0.1)(uconv2)\n",
    "\n",
    "    # 64 -> 128\n",
    "    deconv1 = Conv2DTranspose(16*2, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    conv1 = backbone.layers[11].output\n",
    "    conv1 = ZeroPadding2D(((3,0),(3,0)))(conv1)\n",
    "    print(deconv1.shape, conv1.shape)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    uconv1 = cbam_block(uconv1,'conv1')\n",
    "\n",
    "    uconv1 = Conv2D(16*2, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
    "    uconv1 = residual_block(uconv1, 16*2)\n",
    "    uconv1 = residual_block(uconv1, 16*2)\n",
    "    uconv1 = LeakyReLU(alpha=0.1)(uconv1)\n",
    "\n",
    "    # 128 -> 256\n",
    "    # convm = tf.keras.layers.Cropping2D(cropping=((0, 0), (0, 1)))(convm)\n",
    "    uconv0 = Conv2DTranspose(16*1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)   \n",
    "    uconv0 = Conv2D(16*1, (3, 3), activation=None, padding=\"same\")(uconv0)\n",
    "    uconv0 = residual_block(uconv0, 16*1)\n",
    "    uconv0 = residual_block(uconv0, 16*1)\n",
    "    uconv0 = LeakyReLU(alpha=0.1)(uconv0)\n",
    "\n",
    "    out = Conv2D(nClasses, (1, 1), padding='same')(uconv0)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation('softmax',name=\"Seg\")(out)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=out)\n",
    "    model.load_weights('./自定义分割模型权重.h5')\n",
    "\n",
    "    # 分类结果\n",
    "#     uconv1 = cbam_block(model.get_layer('ClsLeakyReLU').output,'SegModel_Xception_main_conv1')\n",
    "    x = GlobalAveragePooling2D(\n",
    "            name='SegModel_Xception_main_GlobalAveragePooling2D')(model.get_layer('ClsLeakyReLU').output)\n",
    "    dp_1 = Dropout(0.6, name='SegModel_Xception_main_Dropout')(x)\n",
    "    fc2_num_classes = Dense(\n",
    "        2*500,\n",
    "        kernel_initializer='he_normal',\n",
    "        name='SegModel_Xception_main_Dense')(dp_1)\n",
    "    dp_1 = Dropout(0.6, name='SegModel_Xception_main_Dropout1')(fc2_num_classes)\n",
    "    fc2_num_classes = Dense(\n",
    "        2*250,\n",
    "        kernel_initializer='he_normal',\n",
    "        name='SegModel_Xception_main_Dense1')(dp_1)\n",
    "    dp_1 = Dropout(0.6, name='SegModel_Xception_main_Dropout2')(fc2_num_classes)\n",
    "    fc2_num_classes = Dense(\n",
    "        100,\n",
    "        kernel_initializer='he_normal',\n",
    "        name='SegModel_Xception_main_Dense2')(dp_1)\n",
    "    dp_1 = Dropout(0.6, name='SegModel_Xception_main_Dropout3')(fc2_num_classes)\n",
    "    fc2_num_classes = Dense(\n",
    "        2,\n",
    "        kernel_initializer='he_normal',\n",
    "        name='SegModel_Xception_main_Dense_3')(dp_1)\n",
    "    fc2_num_classes = Activation(\n",
    "    'softmax', name='SegModel_Xception')(fc2_num_classes)\n",
    "    model = Model(inputs=model.input, outputs=[model.output,fc2_num_classes])\n",
    "    return model\n",
    "\n",
    "\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "def dice_coeff(x, target, ignore_index = -100, epsilon=1e-6):\n",
    "    # Average of Dice coefficient for all batches, or for a single mask\n",
    "    # 计算一个batch中所有图片某个类别的dice_coefficient\n",
    "    d = 0.\n",
    "    batch_size = tf.shape(x)[0]\n",
    "    for i in range(batch_size):\n",
    "        x_i = tf.reshape(x[i], [-1])\n",
    "        t_i = tf.reshape(target[i], [-1])\n",
    "        if ignore_index >= 0:\n",
    "            # 找出mask中不为ignore_index的区域\n",
    "            roi_mask = tf.not_equal(t_i, ignore_index)\n",
    "            x_i = tf.boolean_mask(x_i, roi_mask)\n",
    "            t_i = tf.boolean_mask(t_i, roi_mask)\n",
    "        inter = tf.reduce_sum(tf.multiply(x_i, t_i))\n",
    "        sets_sum = tf.reduce_sum(x_i) + tf.reduce_sum(t_i)\n",
    "        if sets_sum == 0:\n",
    "            sets_sum = 2 * inter\n",
    "\n",
    "        d += (2 * inter + epsilon) / (sets_sum + epsilon)\n",
    "\n",
    "    return d / tf.cast(batch_size, dtype=tf.float32)\n",
    "\n",
    "\n",
    "def multiclass_dice_coeff(x, target, ignore_index = -100, epsilon=1e-6):\n",
    "    \"\"\"Average of Dice coefficient for all classes\"\"\"\n",
    "    dice = 0.\n",
    "    for channel in range(tf.shape(x)[3]):\n",
    "        dice += dice_coeff(x[:,:,:,channel], target[:,:,:,channel], ignore_index, epsilon)\n",
    "\n",
    "    return dice / tf.cast(tf.shape(x)[3], dtype=tf.float32)\n",
    "\n",
    "def dice_loss(x, target, multiclass = False, ignore_index = -100):\n",
    "    # Dice loss (objective to minimize) between 0 and 1\n",
    "    fn = multiclass_dice_coeff if multiclass else dice_coeff\n",
    "    return 1 - fn(x, target, ignore_index=ignore_index)\n",
    "\n",
    "def ce_dice_loss(y_true, y_pred):\n",
    "    ce_loss = CategoricalCrossentropy()(y_true, y_pred)  # 多类别交叉熵损失\n",
    "    dice_coef = dice_loss(y_pred,y_true,multiclass=True)  # Dice损失\n",
    "\n",
    "    return ce_loss + dice_coef\n",
    "\n",
    "def dice_coef(x, target, multiclass = True, ignore_index = -100):\n",
    "    # Dice loss (objective to minimize) between 0 and 1\n",
    "    fn = multiclass_dice_coeff if multiclass else dice_coeff\n",
    "    return fn(x, target, ignore_index=ignore_index)\n",
    "\n",
    "\n",
    "\n",
    "def setup_to_fine_tune_1(model):\n",
    "    LayersNum = 0\n",
    "    for layer in model.layers:\n",
    "        if not layer.name.startswith('SegModel_Xception'):\n",
    "            layer.trainable = False\n",
    "            LayersNum += 1\n",
    "    print('不可以训练的层有: ' + str(LayersNum) + \"可以训练的层有: \" +\n",
    "          str(len(model.layers) - LayersNum))\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=0.001),\n",
    "                  loss={\"Seg\":ce_dice_loss,\n",
    "                                    \"SegModel_Xception\":categorical_crossentropy},\n",
    "              loss_weights={'Seg': 0.1,\n",
    "                      'SegModel_Xception': 1},\n",
    "              metrics={\"Seg\":[dice_coef,tf.keras.metrics.OneHotMeanIoU(num_classes=3,name='miou')],\n",
    "                                                         \"SegModel_Xception\":\"accuracy\"})\n",
    "\n",
    "def setup_to_fine_tune_2(model):\n",
    "    LayersNum = 0\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "        LayersNum += 1\n",
    "    print('不可以训练的层有: ' + str(LayersNum) + \"可以训练的层有: \" +\n",
    "          str(len(model.layers) - LayersNum))\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=0.0001),loss={\"Seg\":ce_dice_loss,\n",
    "                                    \"SegModel_Xception\":categorical_crossentropy},\n",
    "              loss_weights={'Seg': 1,\n",
    "                      'SegModel_Xception': 1},\n",
    "              metrics={\"Seg\":[dice_coef,tf.keras.metrics.OneHotMeanIoU(num_classes=3,name='miou')],\n",
    "                                                         \"SegModel_Xception\":\"accuracy\"})\n",
    "\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "\n",
    "model = Unet_Xception_ResNetBlock(3,height,width)\n",
    "# model.summary()\n",
    "setup_to_fine_tune_1(model)\n",
    "\n",
    "import os\n",
    "logdir = './callbacks_EarlyStopping_a1'\n",
    "if not os.path.exists(logdir):\n",
    "    os.mkdir(logdir)\n",
    "output_model_file = os.path.join(logdir, \"callbacks_EarlyStopping.h5\")\n",
    "log_dir = os.path.join('log_a1')  #win10下的bug，\n",
    "if not os.path.exists(log_dir):\n",
    "    os.mkdir(log_dir)\n",
    "\n",
    "#回调函数的使用-在训练中数据的保存\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        output_model_file,  #最后模型的保存-加上下面的代码代表就是最优模型的保存\n",
    "        monitor='val_SegModel_Xception_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max'),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_SegModel_Xception_accuracy', min_delta=1e-10, patience=53,mode='max'\n",
    "    ),  #如果模型提前关闭的参数设置，patience参数的意义在于:当迭代次数5次检测指标的值都是比我规定的是小的话，就直接停止模型的训练\n",
    "    #min_delta参数的意思就是:本次训练的测试指标的值与上一次的值的差值是不是比这个阈值要低，如果低的话就停止模型的训练\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_SegModel_Xception_accuracy',\n",
    "                                        patience=10,\n",
    "                                        mode='max',\n",
    "                                        verbose=1,\n",
    "                                        min_delta=1e-9),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=log_dir),\n",
    "]\n",
    "\n",
    "history = model.fit(generate_data_generator(train_generator_input_1,train_generator_input_2),validation_data=\n",
    "        generate_data_generator(valid_generator_input_1,valid_generator_input_2),\n",
    "        steps_per_epoch=train_num_input_1 // batch_size,  #因为迭代器是无限次的，所以要规定什么时候退出\n",
    "        epochs=epochs,\n",
    "        validation_steps=valid_num_input_1 // test_size,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "print('Saving model to disk\\n')\n",
    "model.save('model_Deep_ensemble_learning_1.h5')\n",
    "print(\"history保存\")\n",
    "import pickle\n",
    "with open('model_Deep_ensemble_learning_1.pickle', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)\n",
    "\n",
    "\n",
    "\n",
    "# 第二次训练\n",
    "# 数据集的加载\n",
    "height = 576  #图片的高度\n",
    "width = 768  #图片的长度\n",
    "channels = 3  #彩色图片\n",
    "batch_size = 6  #每一次49个图片\n",
    "test_size=1\n",
    "num_classes = 3  #最后是7分类\n",
    "SEED = 666  # 用于限制多个输入图片的label保持一致，训练集有一个随机扰乱的\n",
    "epochs = 300\n",
    "img_size_input_1 = (height, width)  # 第一个输入图片的维度大小\n",
    "img_size_input_2 = (height, width)  # 第二个输入图片的维度大小\n",
    "# 数据集加载\n",
    "train_dir_input_1 = r\"/HOME/scw7212/run/AZ/Code/congenital_heart_disease/Code/Dataset/Train/IMAGE\"\n",
    "valid_dir_input_1 = r\"/HOME/scw7212/run/AZ/Code/congenital_heart_disease/Code/Dataset/Test/IMAGE\"\n",
    "train_dir_input_2 = r\"/HOME/scw7212/run/AZ/Code/congenital_heart_disease/Code/Dataset/Train/MASK\"\n",
    "valid_dir_input_2 = r\"/HOME/scw7212/run/AZ/Code/congenital_heart_disease/Code/Dataset/Test/MASK\"\n",
    "\n",
    "train_datagen_input_1 = keras.preprocessing.image.ImageDataGenerator(  #这个是专门进行图片进行强化操作处理的,传入一个目录就可以将图片转化成你需要的，且进行数据增强，样本会进行叠加的\n",
    "    rescale=1. / 255, )  #这样就可以新创建出图片了\n",
    "train_generator_input_1 = train_datagen_input_1.flow_from_directory(\n",
    "    train_dir_input_1,  #上面的ImageDataGenerator只是一个迭代器，将图片转化成像素值，这个方法flow_from_directory就可以批量取数据\n",
    "    target_size=img_size_input_1,  #图片大小规定到这个高宽\n",
    "    batch_size=batch_size,  #每一个批次batch_size个图片进行上面的操作\n",
    "    seed=SEED,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\")  #这个指定二进制标签，我们用了binary_crossentropy损失函数\n",
    "valid_datagen_input_1 = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1. / 255)  #验证集不用添加图片，只需要将图片像素值进行规定\n",
    "valid_generator_input_1 = valid_datagen_input_1.flow_from_directory(\n",
    "    valid_dir_input_1,\n",
    "    target_size=img_size_input_1,\n",
    "    batch_size=test_size,\n",
    "    seed=SEED,\n",
    "    shuffle=False,\n",
    "    class_mode=\"categorical\")\n",
    "\n",
    "# mask创建\n",
    "train_datagen_input_2 = keras.preprocessing.image.ImageDataGenerator()  #这样就可以新创建出图片了\n",
    "train_generator_input_2 = train_datagen_input_2.flow_from_directory(\n",
    "    train_dir_input_2,  #上面的ImageDataGenerator只是一个迭代器，将图片转化成像素值，这个方法flow_from_directory就可以批量取数据\n",
    "    target_size=img_size_input_2,  #图片大小规定到这个高宽\n",
    "    batch_size=batch_size,  #每一个批次batch_size个图片进行上面的操作\n",
    "    seed=SEED,\n",
    "    shuffle=True,\n",
    "    color_mode='grayscale',\n",
    "    class_mode=\"categorical\")  #这个指定二进制标签，我们用了binary_crossentropy损失函数\n",
    "valid_datagen_input_2 = keras.preprocessing.image.ImageDataGenerator()  #验证集不用添加图片，只需要将图片像素值进行规定\n",
    "valid_generator_input_2 = valid_datagen_input_2.flow_from_directory(\n",
    "    valid_dir_input_2,\n",
    "    target_size=img_size_input_2,\n",
    "    batch_size=test_size,\n",
    "    seed=SEED,\n",
    "    shuffle=False,\n",
    "    color_mode='grayscale',\n",
    "    class_mode=\"categorical\")\n",
    "train_num_input_1 = train_generator_input_1.samples  #获取训练样本总数\n",
    "train_num_input_2 = train_generator_input_2.samples\n",
    "valid_num_input_1 = valid_generator_input_1.samples  #获取训练样本总数\n",
    "valid_num_input_2 = valid_generator_input_2.samples\n",
    "print(\"样本总数为：\")\n",
    "print(train_num_input_1, train_num_input_2, valid_num_input_1,\n",
    "    valid_num_input_2)\n",
    "\n",
    "model = load_model(r'./callbacks_EarlyStopping_a1/callbacks_EarlyStopping.h5',custom_objects={'ce_dice_loss':ce_dice_loss,'dice_coef':dice_coef})\n",
    "setup_to_fine_tune_2(model)\n",
    "\n",
    "import os\n",
    "logdir = './callbacks_EarlyStopping_a2'\n",
    "if not os.path.exists(logdir):\n",
    "    os.mkdir(logdir)\n",
    "output_model_file = os.path.join(logdir, \"callbacks_EarlyStopping.h5\")\n",
    "log_dir = os.path.join('log_a2')  #win10下的bug，\n",
    "if not os.path.exists(log_dir):\n",
    "    os.mkdir(log_dir)\n",
    "\n",
    "#回调函数的使用-在训练中数据的保存\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        output_model_file,  #最后模型的保存-加上下面的代码代表就是最优模型的保存\n",
    "        monitor='val_SegModel_Xception_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max'),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_SegModel_Xception_accuracy', min_delta=1e-10, patience=53,mode='max'\n",
    "    ),  #如果模型提前关闭的参数设置，patience参数的意义在于:当迭代次数5次检测指标的值都是比我规定的是小的话，就直接停止模型的训练\n",
    "    #min_delta参数的意思就是:本次训练的测试指标的值与上一次的值的差值是不是比这个阈值要低，如果低的话就停止模型的训练\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_SegModel_Xception_accuracy',\n",
    "                                        patience=10,\n",
    "                                        mode='max',\n",
    "                                        verbose=1,\n",
    "                                        min_delta=1e-9),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=log_dir),\n",
    "]\n",
    "\n",
    "history = model.fit(generate_data_generator(train_generator_input_1,train_generator_input_2),validation_data=\n",
    "        generate_data_generator(valid_generator_input_1,valid_generator_input_2),\n",
    "        steps_per_epoch=train_num_input_1 // batch_size,  #因为迭代器是无限次的，所以要规定什么时候退出\n",
    "        epochs=epochs,\n",
    "        validation_steps=valid_num_input_1 // test_size,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "print('Saving model to disk\\n')\n",
    "model.save('model_Deep_ensemble_learning_2.h5')\n",
    "print(\"history保存\")\n",
    "import pickle\n",
    "with open('model_Deep_ensemble_learning_2.pickle', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76477c02-b2b7-45fd-a733-f81830862bfc",
   "metadata": {},
   "source": [
    "# 模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc1372e-f773-44b2-a086-e1fdd3cf87d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集的加载\n",
    "height = 576  #图片的高度\n",
    "width = 768  #图片的长度\n",
    "channels = 3  #彩色图片\n",
    "batch_size = 1  #每一次49个图片\n",
    "num_classes = 3  #最后是7分类\n",
    "SEED = 666  # 用于限制多个输入图片的label保持一致，训练集有一个随机扰乱的\n",
    "epochs = 300\n",
    "img_size_input_1 = (height, width)  # 第一个输入图片的维度大小\n",
    "img_size_input_2 = (height, width)  # 第二个输入图片的维度大小\n",
    "# 数据集加载\n",
    "train_dir_input_1 = r\"/HOME/scw7212/run/AZ/Code/congenital_heart_disease/Code/Dataset/Train/IMAGE\"\n",
    "valid_dir_input_1 = r\"/HOME/scw7212/run/AZ/Code/congenital_heart_disease/Code/Dataset/Test/IMAGE\"\n",
    "train_dir_input_2 = r\"/HOME/scw7212/run/AZ/Code/congenital_heart_disease/Code/Dataset/Train/MASK\"\n",
    "valid_dir_input_2 = r\"/HOME/scw7212/run/AZ/Code/congenital_heart_disease/Code/Dataset/Test/MASK\"\n",
    "\n",
    "train_datagen_input_1 = keras.preprocessing.image.ImageDataGenerator(  #这个是专门进行图片进行强化操作处理的,传入一个目录就可以将图片转化成你需要的，且进行数据增强，样本会进行叠加的\n",
    "    rescale=1. / 255, )  #这样就可以新创建出图片了\n",
    "train_generator_input_1 = train_datagen_input_1.flow_from_directory(\n",
    "    train_dir_input_1,  #上面的ImageDataGenerator只是一个迭代器，将图片转化成像素值，这个方法flow_from_directory就可以批量取数据\n",
    "    target_size=img_size_input_1,  #图片大小规定到这个高宽\n",
    "    batch_size=batch_size,  #每一个批次batch_size个图片进行上面的操作\n",
    "    seed=SEED,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\")  #这个指定二进制标签，我们用了binary_crossentropy损失函数\n",
    "valid_datagen_input_1 = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1. / 255)  #验证集不用添加图片，只需要将图片像素值进行规定\n",
    "valid_generator_input_1 = valid_datagen_input_1.flow_from_directory(\n",
    "    valid_dir_input_1,\n",
    "    target_size=img_size_input_1,\n",
    "    batch_size=batch_size,\n",
    "    seed=SEED,\n",
    "    shuffle=False,\n",
    "    class_mode=\"categorical\")\n",
    "\n",
    "# mask创建\n",
    "train_datagen_input_2 = keras.preprocessing.image.ImageDataGenerator()  #这样就可以新创建出图片了\n",
    "train_generator_input_2 = train_datagen_input_2.flow_from_directory(\n",
    "    train_dir_input_2,  #上面的ImageDataGenerator只是一个迭代器，将图片转化成像素值，这个方法flow_from_directory就可以批量取数据\n",
    "    target_size=img_size_input_2,  #图片大小规定到这个高宽\n",
    "    batch_size=batch_size,  #每一个批次batch_size个图片进行上面的操作\n",
    "    seed=SEED,\n",
    "    shuffle=True,\n",
    "    color_mode='grayscale',\n",
    "    class_mode=\"categorical\")  #这个指定二进制标签，我们用了binary_crossentropy损失函数\n",
    "valid_datagen_input_2 = keras.preprocessing.image.ImageDataGenerator()  #验证集不用添加图片，只需要将图片像素值进行规定\n",
    "valid_generator_input_2 = valid_datagen_input_2.flow_from_directory(\n",
    "    valid_dir_input_2,\n",
    "    target_size=img_size_input_2,\n",
    "    batch_size=batch_size,\n",
    "    seed=SEED,\n",
    "    shuffle=False,\n",
    "    color_mode='grayscale',\n",
    "    class_mode=\"categorical\")\n",
    "train_num_input_1 = train_generator_input_1.samples  #获取训练样本总数\n",
    "train_num_input_2 = train_generator_input_2.samples\n",
    "valid_num_input_1 = valid_generator_input_1.samples  #获取训练样本总数\n",
    "valid_num_input_2 = valid_generator_input_2.samples\n",
    "print(\"样本总数为：\")\n",
    "print(train_num_input_1, train_num_input_2, valid_num_input_1,\n",
    "    valid_num_input_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5766668f-865b-4488-b9b6-2c3d2e4f42a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_generator(generator_input_1, generator_input_2):\n",
    "    while True:\n",
    "        x_data, label_x = generator_input_1.next()\n",
    "        mask_data, label_mask = generator_input_2.next()\n",
    "        # 这一句代码代表输入的多个类型的图片label是一致的\n",
    "        assert np.array(label_x).all() == np.array(label_mask).all(), '数据集产出失败'\n",
    "        # 代表输入的图片与输出的label的维度指定\n",
    "        yield np.array(x_data),{\"Seg\":tf.one_hot(np.array(tf.squeeze(mask_data,axis=-1)),depth=3),\n",
    "                                \"SegModel_Xception\":label_x}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ed3cc9-4473-4dd4-9828-86bfd4f94f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import CategoricalCrossentropy\n",
    "def dice_coeff(x, target, ignore_index = -100, epsilon=1e-6):\n",
    "    # Average of Dice coefficient for all batches, or for a single mask\n",
    "    # 计算一个batch中所有图片某个类别的dice_coefficient\n",
    "    d = 0.\n",
    "    batch_size = tf.shape(x)[0]\n",
    "    for i in range(batch_size):\n",
    "        x_i = tf.reshape(x[i], [-1])\n",
    "        t_i = tf.reshape(target[i], [-1])\n",
    "        if ignore_index >= 0:\n",
    "            # 找出mask中不为ignore_index的区域\n",
    "            roi_mask = tf.not_equal(t_i, ignore_index)\n",
    "            x_i = tf.boolean_mask(x_i, roi_mask)\n",
    "            t_i = tf.boolean_mask(t_i, roi_mask)\n",
    "        inter = tf.reduce_sum(tf.multiply(x_i, t_i))\n",
    "        sets_sum = tf.reduce_sum(x_i) + tf.reduce_sum(t_i)\n",
    "        if sets_sum == 0:\n",
    "            sets_sum = 2 * inter\n",
    "\n",
    "        d += (2 * inter + epsilon) / (sets_sum + epsilon)\n",
    "\n",
    "    return d / tf.cast(batch_size, dtype=tf.float32)\n",
    "\n",
    "\n",
    "def multiclass_dice_coeff(x, target, ignore_index = -100, epsilon=1e-6):\n",
    "    \"\"\"Average of Dice coefficient for all classes\"\"\"\n",
    "    dice = 0.\n",
    "    for channel in range(tf.shape(x)[3]):\n",
    "        dice += dice_coeff(x[:,:,:,channel], target[:,:,:,channel], ignore_index, epsilon)\n",
    "\n",
    "    return dice / tf.cast(tf.shape(x)[3], dtype=tf.float32)\n",
    "\n",
    "def dice_loss(x, target, multiclass = False, ignore_index = -100):\n",
    "    # Dice loss (objective to minimize) between 0 and 1\n",
    "    fn = multiclass_dice_coeff if multiclass else dice_coeff\n",
    "    return 1 - fn(x, target, ignore_index=ignore_index)\n",
    "\n",
    "def ce_dice_loss(y_true, y_pred):\n",
    "    ce_loss = CategoricalCrossentropy()(y_true, y_pred)  # 多类别交叉熵损失\n",
    "    dice_coef = dice_loss(y_pred,y_true,multiclass=True)  # Dice损失\n",
    "\n",
    "    return ce_loss + dice_coef\n",
    "\n",
    "def dice_coef(x, target, multiclass = True, ignore_index = -100):\n",
    "    # Dice loss (objective to minimize) between 0 and 1\n",
    "    fn = multiclass_dice_coeff if multiclass else dice_coeff\n",
    "    return fn(x, target, ignore_index=ignore_index)\n",
    "\n",
    "model = load_model('./callbacks_EarlyStopping_a2/callbacks_EarlyStopping.h5',\n",
    "                   custom_objects={'ce_dice_loss':ce_dice_loss,'dice_coef':dice_coef})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc83a874-c370-43d4-b8ed-a72aeb17dd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = []\n",
    "test_mask = []\n",
    "test_pre_label = []\n",
    "test_pre_mask = []\n",
    "test_image = []\n",
    "\n",
    "test_loss = []\n",
    "test_coef = []\n",
    "test_iou = []\n",
    "\n",
    "count = 0\n",
    "for image,label in generate_data_generator(valid_generator_input_1,valid_generator_input_2):\n",
    "    mask_label,y_label= label['Seg'],label['SegModel_Xception']\n",
    "    y_pre_mask,y_pre_label = model.predict(image)\n",
    "    \n",
    "    test_loss.append(ce_dice_loss(mask_label,y_pre_mask))\n",
    "    test_coef.append(dice_coef(y_pre_mask,mask_label))\n",
    "    test_iou.append(tf.keras.metrics.OneHotMeanIoU(num_classes=3,name='miou')(mask_label,y_pre_mask))\n",
    "    \n",
    "    test_label.append(y_label)\n",
    "    test_pre_label.append(y_pre_label)\n",
    "    \n",
    "    test_image.append(image)\n",
    "    \n",
    "    test_mask.append(mask_label)\n",
    "    test_pre_mask.append(y_pre_mask)\n",
    "    \n",
    "    count+=1\n",
    "    if count == 53:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4424cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 百分位法的置信区间\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "def auc_boot(actual, predicted):\n",
    "    # 计算AUC\n",
    "    actual = np.array(actual)\n",
    "    predicted = np.array(predicted)\n",
    "    auc = metrics.accuracy_score(actual, predicted)\n",
    "\n",
    "    # 执行bootstrap重采样来计算AUC的置信区间\n",
    "    n_bootstraps = 10000\n",
    "    auc_scores = []\n",
    "    for i in range(n_bootstraps):\n",
    "        np.random.seed(i)\n",
    "        indices = np.random.choice(range(len(actual)), len(actual), replace=True)\n",
    "        # print(indices)\n",
    "        auc_bootstrap = metrics.roc_auc_score(actual[indices], predicted[indices])\n",
    "        auc_scores.append(auc_bootstrap)\n",
    "    print(auc_scores)\n",
    "    low,height = np.percentile(auc_scores, [2.5, 97.5])\n",
    "    return auc,low,height\n",
    "auc_boot(y_label,test_pre_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acbc4c0-d7f9-4058-814d-9888f899fddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(test_loss).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044c5ae0-429f-49f6-b04b-78fda2aac956",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(test_coef).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a859b63-cce6-4803-8b50-7cad4222fc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(test_iou).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab16b8f9-453b-4464-90de-bbcf84aa1727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed=666\n",
    "aaa = []\n",
    "aaa.append(random.randint(0,52))\n",
    "aaa.append(random.randint(0,52))\n",
    "aaa.append(random.randint(0,52))\n",
    "aaa.append(random.randint(0,52))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80945af0-ffbc-43f1-83ad-aff52694bebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 创建一个包含四个子图的图像布局\n",
    "fig, axes = plt.subplots(2, 2, figsize=(7, 7))\n",
    "\n",
    "# 在每个子图中绘制内容\n",
    "axes[0, 0].imshow(np.array(test_image).squeeze()[aaa[0]])  # 第一个子图\n",
    "axes[0, 1].imshow(np.array(test_image).squeeze()[aaa[1]])  # 第二个子图\n",
    "axes[1, 0].imshow(np.array(test_image).squeeze()[aaa[2]])  # 第一个子图\n",
    "axes[1, 1].imshow(np.array(test_image).squeeze()[aaa[3]])  # 第一个子图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b6d5ae-fef2-4473-88e4-293530456024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 创建一个包含四个子图的图像布局\n",
    "fig, axes = plt.subplots(2, 2, figsize=(7, 7))\n",
    "\n",
    "# 在每个子图中绘制内容\n",
    "axes[0, 0].imshow(np.argmax(np.array(test_mask).squeeze(),axis=-1).reshape((53, 576, 768,1))[aaa[0]],cmap='gray')  # 第一个子图\n",
    "axes[0, 1].imshow(np.argmax(np.array(test_mask).squeeze(),axis=-1).reshape((53, 576, 768,1))[aaa[1]],cmap='gray')  # 第一个子图\n",
    "axes[1, 0].imshow(np.argmax(np.array(test_mask).squeeze(),axis=-1).reshape((53, 576, 768,1))[aaa[2]],cmap='gray')  # 第一个子图\n",
    "axes[1, 1].imshow(np.argmax(np.array(test_mask).squeeze(),axis=-1).reshape((53, 576, 768,1))[aaa[3]],cmap='gray')  # 第一个子图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9328788-7a81-40a1-8c5c-af1a4deb4551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 创建一个包含四个子图的图像布局\n",
    "fig, axes = plt.subplots(2, 2, figsize=(7, 7))\n",
    "\n",
    "# 在每个子图中绘制内容\n",
    "axes[0, 0].imshow(np.argmax(np.array(test_pre_mask).squeeze(),axis=-1).reshape((53, 576, 768,1))[aaa[0]],cmap='gray')  # 第一个子图\n",
    "axes[0, 1].imshow(np.argmax(np.array(test_pre_mask).squeeze(),axis=-1).reshape((53, 576, 768,1))[aaa[1]],cmap='gray')  # 第一个子图\n",
    "axes[1, 0].imshow(np.argmax(np.array(test_pre_mask).squeeze(),axis=-1).reshape((53, 576, 768,1))[aaa[2]],cmap='gray')  # 第一个子图\n",
    "axes[1, 1].imshow(np.argmax(np.array(test_pre_mask).squeeze(),axis=-1).reshape((53, 576, 768,1))[aaa[3]],cmap='gray')  # 第一个子图"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d75734-083f-414f-8cfa-708bb8953612",
   "metadata": {},
   "source": [
    "# 分类指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605286ef-5542-401e-b40b-0318a757e551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "test_predict_class_indices = np.argmax(np.array(test_pre_label).squeeze(), axis = 1)#找到预测类别是哪一个   哪个值最大就是哪一类\n",
    "test_label = np.argmax(np.array(test_label).squeeze(), axis = 1)#找到预测类别是哪一个   哪个值最大就是哪一类\n",
    "print(classification_report(test_label, test_predict_class_indices,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a296ee7d-7b24-4069-bb8d-8405bdbd2a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_label, test_predict_class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3cd83c-c289-489d-8204-7dea9a94228e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.array(test_pre_label).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30df65d1-0101-4726-aa17-f83224bcae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score,precision_score,f1_score,roc_auc_score\n",
    "roc_auc_score(test_label, np.array(test_pre_label).squeeze()[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99699317-5837-4e8a-bcb2-dce0e637c562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 创建一个包含四个子图的图像布局\n",
    "fig, axes = plt.subplots(2, 2, figsize=(7, 7))\n",
    "\n",
    "# 在每个子图中绘制内容\n",
    "axes[0, 0].imshow(np.array(test_image).squeeze()[-1])  # 第一个子图\n",
    "axes[0, 1].imshow(np.array(test_image).squeeze()[-2])  # 第一个子图\n",
    "axes[1, 0].imshow(np.array(test_image).squeeze()[-10])  # 第一个子图\n",
    "axes[1, 1].imshow(np.array(test_image).squeeze()[28])  # 第一个子图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa80912-3988-4c28-813b-64d40cdc3512",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label[[-1,-2,-10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc63a8d-e6cf-4a11-9db5-6df6a820ca6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(test_pre_label).squeeze()[[-1,-2,-10],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dbd32f-ad66-4a80-bac6-bd82b430dfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label[28],np.array(test_pre_label).squeeze()[28,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c61f2c9-375b-4cd8-ac7d-314d233294e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "time.sleep(5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fe8b54-0c71-48d6-b3ec-eeda05a13231",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scancel 1729105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e348d7e8-0f35-43c7-afb1-ad90aa0ab23a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e64530a-c588-43e0-90b7-666236327e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06baad29-6709-4800-b451-f2c0eae522f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba70d97a-a7b4-4567-bb13-d9a41ca3ffdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2fff64-3a1f-463b-a04e-2c648b5c3e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245f13ea-1dc3-4da3-b969-4342cd91c6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
